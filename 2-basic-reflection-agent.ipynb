{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35cdaa7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-08T05:40:56.545942Z",
     "iopub.status.busy": "2025-08-08T05:40:56.544634Z",
     "iopub.status.idle": "2025-08-08T05:40:58.821686Z",
     "shell.execute_reply": "2025-08-08T05:40:58.820779Z"
    },
    "papermill": {
     "duration": 2.285453,
     "end_time": "2025-08-08T05:40:58.823541",
     "exception": false,
     "start_time": "2025-08-08T05:40:56.538088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ff203ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:40:58.834152Z",
     "iopub.status.busy": "2025-08-08T05:40:58.833588Z",
     "iopub.status.idle": "2025-08-08T05:41:08.881874Z",
     "shell.execute_reply": "2025-08-08T05:41:08.880675Z"
    },
    "papermill": {
     "duration": 10.055527,
     "end_time": "2025-08-08T05:41:08.883808",
     "exception": false,
     "start_time": "2025-08-08T05:40:58.828281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\r\n",
      "Collecting langchain-community\r\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting langchain-nvidia-ai-endpoints\r\n",
      "  Downloading langchain_nvidia_ai_endpoints-0.3.14-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.66)\r\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\r\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.1)\r\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.4)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.13)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\r\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\r\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\r\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\r\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-nvidia-ai-endpoints)\r\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\r\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.66->langchain)\r\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\r\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.2.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.2.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\r\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\r\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\r\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\r\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\r\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langchain_nvidia_ai_endpoints-0.3.14-py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\r\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\r\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\r\n",
      "Installing collected packages: filetype, python-dotenv, packaging, httpx-sse, pydantic-settings, langchain-nvidia-ai-endpoints, langchain-community\r\n",
      "  Attempting uninstall: packaging\r\n",
      "    Found existing installation: packaging 25.0\r\n",
      "    Uninstalling packaging-25.0:\r\n",
      "      Successfully uninstalled packaging-25.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\r\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "pandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "dataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "bigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed filetype-1.2.0 httpx-sse-0.4.1 langchain-community-0.3.27 langchain-nvidia-ai-endpoints-0.3.14 packaging-24.2 pydantic-settings-2.10.1 python-dotenv-1.1.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community langchain-nvidia-ai-endpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd25537e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:08.897856Z",
     "iopub.status.busy": "2025-08-08T05:41:08.897440Z",
     "iopub.status.idle": "2025-08-08T05:41:11.159812Z",
     "shell.execute_reply": "2025-08-08T05:41:11.158189Z"
    },
    "papermill": {
     "duration": 2.271832,
     "end_time": "2025-08-08T05:41:11.161967",
     "exception": false,
     "start_time": "2025-08-08T05:41:08.890135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12956ab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:11.176012Z",
     "iopub.status.busy": "2025-08-08T05:41:11.175271Z",
     "iopub.status.idle": "2025-08-08T05:41:11.495301Z",
     "shell.execute_reply": "2025-08-08T05:41:11.494005Z"
    },
    "papermill": {
     "duration": 0.329444,
     "end_time": "2025-08-08T05:41:11.497646",
     "exception": false,
     "start_time": "2025-08-08T05:41:11.168202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "nvidia_api_key = UserSecretsClient().get_secret(\"NVIDIA_API_KEY\")\n",
    "nvidia_model_name = UserSecretsClient().get_secret(\"NVIDIA_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab4bab30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:11.513531Z",
     "iopub.status.busy": "2025-08-08T05:41:11.513205Z",
     "iopub.status.idle": "2025-08-08T05:41:11.519374Z",
     "shell.execute_reply": "2025-08-08T05:41:11.518235Z"
    },
    "papermill": {
     "duration": 0.017036,
     "end_time": "2025-08-08T05:41:11.521234",
     "exception": false,
     "start_time": "2025-08-08T05:41:11.504198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\", \n",
    "            \"You are a twitter techie influencer assistant tasked with weiting excellent twitter posts.\"\n",
    "            \"Generate the best twitter post possible for the user's request.\"\n",
    "            \"If the user provides critique , respond with a revised version of your previous attempts.\",\n",
    "        \n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name = \"messages\"),\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c172ef24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:11.537332Z",
     "iopub.status.busy": "2025-08-08T05:41:11.536869Z",
     "iopub.status.idle": "2025-08-08T05:41:11.543406Z",
     "shell.execute_reply": "2025-08-08T05:41:11.542181Z"
    },
    "papermill": {
     "duration": 0.017617,
     "end_time": "2025-08-08T05:41:11.545525",
     "exception": false,
     "start_time": "2025-08-08T05:41:11.527908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " reflection_prompt = ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\n",
    "             \"system\",\n",
    "             \"You are a viral twitter influencer grading a tweet. Generate critique and recomendations for the user's tweet.\"\n",
    "             \"Always provide detailed recommendations, including requests for length, virality, style, etc.\",\n",
    "         ),\n",
    "         MessagesPlaceholder(variable_name = \"messages\"),\n",
    "     ]\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17027540",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:11.559907Z",
     "iopub.status.busy": "2025-08-08T05:41:11.559486Z",
     "iopub.status.idle": "2025-08-08T05:41:11.590049Z",
     "shell.execute_reply": "2025-08-08T05:41:11.588826Z"
    },
    "papermill": {
     "duration": 0.040502,
     "end_time": "2025-08-08T05:41:11.592532",
     "exception": false,
     "start_time": "2025-08-08T05:41:11.552030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm = ChatNVIDIA(\n",
    "    model = nvidia_model_name,\n",
    "    api_key = nvidia_api_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783fb64d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:11.610577Z",
     "iopub.status.busy": "2025-08-08T05:41:11.610157Z",
     "iopub.status.idle": "2025-08-08T05:41:11.616240Z",
     "shell.execute_reply": "2025-08-08T05:41:11.614942Z"
    },
    "papermill": {
     "duration": 0.01884,
     "end_time": "2025-08-08T05:41:11.618268",
     "exception": false,
     "start_time": "2025-08-08T05:41:11.599428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_chain = generation_prompt | llm\n",
    "\n",
    "reflection_chain = reflection_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45cf05cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:11.633430Z",
     "iopub.status.busy": "2025-08-08T05:41:11.633013Z",
     "iopub.status.idle": "2025-08-08T05:41:18.560388Z",
     "shell.execute_reply": "2025-08-08T05:41:18.558686Z"
    },
    "papermill": {
     "duration": 6.937448,
     "end_time": "2025-08-08T05:41:18.562601",
     "exception": false,
     "start_time": "2025-08-08T05:41:11.625153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\r\n",
      "  Downloading langgraph-0.6.4-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.66)\r\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\r\n",
      "  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\r\n",
      "  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\r\n",
      "Collecting langgraph-sdk<0.3.0,>=0.2.0 (from langgraph)\r\n",
      "  Downloading langgraph_sdk-0.2.0-py3-none-any.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\r\n",
      "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\r\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.1)\r\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\r\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\r\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.0)\r\n",
      "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\r\n",
      "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting langchain-core>=0.1 (from langgraph)\r\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\r\n",
      "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\r\n",
      "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.10.18)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.9.0)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (2025.6.15)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\r\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.10)\r\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\r\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\r\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.1)\r\n",
      "Downloading langgraph-0.6.4-py3-none-any.whl (153 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.2/153.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\r\n",
      "Downloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading langgraph_sdk-0.2.0-py3-none-any.whl (50 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langgraph-prebuilt, langgraph\r\n",
      "  Attempting uninstall: langchain-core\r\n",
      "    Found existing installation: langchain-core 0.3.66\r\n",
      "    Uninstalling langchain-core-0.3.66:\r\n",
      "      Successfully uninstalled langchain-core-0.3.66\r\n",
      "Successfully installed langchain-core-0.3.74 langgraph-0.6.4 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.0 ormsgpack-1.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ba0e1c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.586546Z",
     "iopub.status.busy": "2025-08-08T05:41:18.586198Z",
     "iopub.status.idle": "2025-08-08T05:41:18.784666Z",
     "shell.execute_reply": "2025-08-08T05:41:18.783774Z"
    },
    "papermill": {
     "duration": 0.208546,
     "end_time": "2025-08-08T05:41:18.786382",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.577836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Sequence\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langgraph.graph import END, MessageGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a5cbc2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.801852Z",
     "iopub.status.busy": "2025-08-08T05:41:18.801505Z",
     "iopub.status.idle": "2025-08-08T05:41:18.806207Z",
     "shell.execute_reply": "2025-08-08T05:41:18.805526Z"
    },
    "papermill": {
     "duration": 0.014101,
     "end_time": "2025-08-08T05:41:18.807673",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.793572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/4047370416.py:1: LangGraphDeprecatedSinceV10: MessageGraph is deprecated in LangGraph v1.0.0, to be removed in v2.0.0. Please use StateGraph with a `messages` key instead. Deprecated in LangGraph V1.0 to be removed in V2.0.\n",
      "  graph = MessageGraph()\n"
     ]
    }
   ],
   "source": [
    "graph = MessageGraph()\n",
    "\n",
    "REFLECT = \"reflect\"\n",
    "GENERATE = \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9936e5e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.823175Z",
     "iopub.status.busy": "2025-08-08T05:41:18.822832Z",
     "iopub.status.idle": "2025-08-08T05:41:18.828608Z",
     "shell.execute_reply": "2025-08-08T05:41:18.827572Z"
    },
    "papermill": {
     "duration": 0.015647,
     "end_time": "2025-08-08T05:41:18.830410",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.814763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_node(state):\n",
    "    return generation_chain.invoke({\n",
    "        \"messages\": state\n",
    "    }\n",
    "    \n",
    "    )\n",
    "\n",
    "def reflect_node(messages):\n",
    "    response = reflection_chain.invoke({\n",
    "        \"messages\": messages\n",
    "    }\n",
    "        \n",
    "    )\n",
    "    return [HumanMessage(content = response.content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3806ef42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.845742Z",
     "iopub.status.busy": "2025-08-08T05:41:18.845376Z",
     "iopub.status.idle": "2025-08-08T05:41:18.852640Z",
     "shell.execute_reply": "2025-08-08T05:41:18.851780Z"
    },
    "papermill": {
     "duration": 0.016546,
     "end_time": "2025-08-08T05:41:18.854051",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.837505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x7cc8409095d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(GENERATE, generate_node)\n",
    "graph.add_node(REFLECT, reflect_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8859d65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.870205Z",
     "iopub.status.busy": "2025-08-08T05:41:18.869673Z",
     "iopub.status.idle": "2025-08-08T05:41:18.876297Z",
     "shell.execute_reply": "2025-08-08T05:41:18.875050Z"
    },
    "papermill": {
     "duration": 0.016502,
     "end_time": "2025-08-08T05:41:18.877883",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.861381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x7cc8409095d0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.set_entry_point(GENERATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd18c687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.894276Z",
     "iopub.status.busy": "2025-08-08T05:41:18.893895Z",
     "iopub.status.idle": "2025-08-08T05:41:18.899242Z",
     "shell.execute_reply": "2025-08-08T05:41:18.898111Z"
    },
    "papermill": {
     "duration": 0.015488,
     "end_time": "2025-08-08T05:41:18.900825",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.885337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if (len(state) > 4):\n",
    "        return END\n",
    "    return REFLECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9e4cd2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.917817Z",
     "iopub.status.busy": "2025-08-08T05:41:18.917339Z",
     "iopub.status.idle": "2025-08-08T05:41:18.924009Z",
     "shell.execute_reply": "2025-08-08T05:41:18.922987Z"
    },
    "papermill": {
     "duration": 0.017303,
     "end_time": "2025-08-08T05:41:18.925563",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.908260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x7cc8409095d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_conditional_edges(GENERATE, should_continue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8e10b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.942587Z",
     "iopub.status.busy": "2025-08-08T05:41:18.942181Z",
     "iopub.status.idle": "2025-08-08T05:41:18.948933Z",
     "shell.execute_reply": "2025-08-08T05:41:18.947808Z"
    },
    "papermill": {
     "duration": 0.017407,
     "end_time": "2025-08-08T05:41:18.950541",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.933134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.message.MessageGraph at 0x7cc8409095d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_edge(REFLECT, GENERATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdee2b72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.968499Z",
     "iopub.status.busy": "2025-08-08T05:41:18.968193Z",
     "iopub.status.idle": "2025-08-08T05:41:18.975692Z",
     "shell.execute_reply": "2025-08-08T05:41:18.974594Z"
    },
    "papermill": {
     "duration": 0.018883,
     "end_time": "2025-08-08T05:41:18.977845",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.958962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "860a8e08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:18.994936Z",
     "iopub.status.busy": "2025-08-08T05:41:18.994450Z",
     "iopub.status.idle": "2025-08-08T05:41:23.227873Z",
     "shell.execute_reply": "2025-08-08T05:41:23.226082Z"
    },
    "papermill": {
     "duration": 4.243906,
     "end_time": "2025-08-08T05:41:23.229927",
     "exception": false,
     "start_time": "2025-08-08T05:41:18.986021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grandalf\r\n",
      "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from grandalf) (3.0.9)\r\n",
      "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: grandalf\r\n",
      "Successfully installed grandalf-0.8\r\n"
     ]
    }
   ],
   "source": [
    "!pip install grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfd6a684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:23.248284Z",
     "iopub.status.busy": "2025-08-08T05:41:23.247902Z",
     "iopub.status.idle": "2025-08-08T05:41:23.313789Z",
     "shell.execute_reply": "2025-08-08T05:41:23.312609Z"
    },
    "papermill": {
     "duration": 0.077527,
     "end_time": "2025-08-08T05:41:23.315658",
     "exception": false,
     "start_time": "2025-08-08T05:41:23.238131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+  \n",
      "| __start__ |  \n",
      "+-----------+  \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      "+----------+   \n",
      "| generate |   \n",
      "+----------+   \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      " +---------+   \n",
      " | __end__ |   \n",
      " +---------+   \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(app.get_graph().print_ascii())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e79a4fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:23.334157Z",
     "iopub.status.busy": "2025-08-08T05:41:23.333548Z",
     "iopub.status.idle": "2025-08-08T05:41:23.342193Z",
     "shell.execute_reply": "2025-08-08T05:41:23.340793Z"
    },
    "papermill": {
     "duration": 0.019236,
     "end_time": "2025-08-08T05:41:23.343752",
     "exception": false,
     "start_time": "2025-08-08T05:41:23.324516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__(<p>__start__</p>)\n",
      "\tgenerate(generate)\n",
      "\treflect(reflect)\n",
      "\t__end__(<p>__end__</p>)\n",
      "\t__start__ --> generate;\n",
      "\tgenerate --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef48ddba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:23.361185Z",
     "iopub.status.busy": "2025-08-08T05:41:23.360886Z",
     "iopub.status.idle": "2025-08-08T05:41:24.174328Z",
     "shell.execute_reply": "2025-08-08T05:41:24.172932Z"
    },
    "papermill": {
     "duration": 0.824319,
     "end_time": "2025-08-08T05:41:24.176310",
     "exception": false,
     "start_time": "2025-08-08T05:41:23.351991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "secret_value_0 = UserSecretsClient().get_secret(\"LANGSMITH_API_KEY\")\n",
    "secret_value_1 = UserSecretsClient().get_secret(\"LANGSMITH_ENDPOINT\")\n",
    "secret_value_2 = UserSecretsClient().get_secret(\"LANGSMITH_PROJECT\")\n",
    "secret_value_3 = UserSecretsClient().get_secret(\"LANGSMITH_TRACING\")\n",
    "secret_value_4 = UserSecretsClient().get_secret(\"NVIDIA_API_KEY\")\n",
    "secret_value_5 = UserSecretsClient().get_secret(\"NVIDIA_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d922a86a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:24.194475Z",
     "iopub.status.busy": "2025-08-08T05:41:24.194181Z",
     "iopub.status.idle": "2025-08-08T05:41:49.743176Z",
     "shell.execute_reply": "2025-08-08T05:41:49.742175Z"
    },
    "papermill": {
     "duration": 25.560735,
     "end_time": "2025-08-08T05:41:49.745585",
     "exception": false,
     "start_time": "2025-08-08T05:41:24.184850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = app.invoke(HumanMessage(content = \"Ai agents taking over content creation\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98738a99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-08T05:41:49.771222Z",
     "iopub.status.busy": "2025-08-08T05:41:49.770836Z",
     "iopub.status.idle": "2025-08-08T05:41:49.778435Z",
     "shell.execute_reply": "2025-08-08T05:41:49.777414Z"
    },
    "papermill": {
     "duration": 0.019048,
     "end_time": "2025-08-08T05:41:49.780228",
     "exception": false,
     "start_time": "2025-08-08T05:41:49.761180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Ai agents taking over content creation', additional_kwargs={}, response_metadata={}, id='fe4092cd-8be2-415f-80c6-ff63c73f6ce7'), AIMessage(content='Here\\'s a Twitter post for the topic \"AI agents taking over content creation\":\\n\\n**Initial Post**\\n\\n\"The AI revolution has arrived! As machines become increasingly capable of creating high-quality content, the lines between human and artificial creativity start to blur. Will AI agents take over content creation? Should we embrace the change or fear the machines? #AIContent #FutureOfWork\"\\n\\nLet me know if you\\'d like me to revise or expand on this post!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Here\\'s a Twitter post for the topic \"AI agents taking over content creation\":\\n\\n**Initial Post**\\n\\n\"The AI revolution has arrived! As machines become increasingly capable of creating high-quality content, the lines between human and artificial creativity start to blur. Will AI agents take over content creation? Should we embrace the change or fear the machines? #AIContent #FutureOfWork\"\\n\\nLet me know if you\\'d like me to revise or expand on this post!', 'token_usage': {'prompt_tokens': 64, 'total_tokens': 153, 'completion_tokens': 89}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-70b-instruct'}, id='run--47fcc98f-303f-4898-a359-646e388e8bd5-0', usage_metadata={'input_tokens': 64, 'output_tokens': 89, 'total_tokens': 153}, role='assistant'), HumanMessage(content='Here\\'s my critique and recommendations for the tweet:\\n\\n**Grade:** B+ (87%)\\n\\n**Critique:**\\n\\nThe tweet is a great starting point, but it can be improved to increase its virality and engagement. Here\\'s what works well:\\n\\n* The topic is relevant and timely, exploring the intersection of AI and content creation.\\n* The tweet raises a thought-provoking question, encouraging users to share their opinions.\\n* The hashtags #AIContent and #FutureOfWork are niche but specific, targeting the right audience.\\n\\nHowever, here\\'s what can be improved:\\n\\n* **Length:** The tweet is a bit too short, making it feel somewhat incomplete. Consider expanding it to 280 characters to provide more context or add a brief example.\\n* **Style:** The tone is somewhat neutral, which can make the tweet feel less engaging. Consider adding a bit of personality or a bold statement to spark more interest.\\n* **Call-to-Action (CTA):** While the tweet asks a question, it doesn\\'t explicitly encourage users to share their thoughts. Add a clear CTA, such as \" Share your thoughts: Will AI agents take over content creation? \"\\n\\n**Recommendations:**\\n\\n1. **Expand on the topic:** Add a brief example or statistic to illustrate the impact of AI on content creation. This will help make the tweet more informative and engaging.\\n\\nExample: \"Did you know that AI-generated content can be up to 30% more engaging than human-created content? As machines become increasingly capable of creating high-quality content, the lines between human and artificial creativity start to blur. Will AI agents take over content creation? #AIContent #FutureOfWork\"\\n\\n2. **Add a bold statement or opinion:** Inject some personality into the tweet by sharing a strong opinion or prediction. This will help spark more interest and debate.\\n\\nExample: \"AI agents are not just taking over content creation, they\\'re revolutionizing it! By 2025, I predict that AI-generated content will dominate most industries. Share your thoughts: Will AI agents take over content creation? #AIContent #FutureOfWork\"\\n\\n3. **Include a visual element:** Consider adding an eye-catching image, graphic, or video to the tweet to break up the text and make it more visually appealing.\\n\\nExample: Create a simple graphic with a bold headline and a few statistics about AI in content creation. Share the image with the tweet and use relevant hashtags.\\n\\nBy implementing these recommendations, you\\'ll make the tweet more engaging, informative, and likely to spark a conversation.', additional_kwargs={}, response_metadata={}, id='e01df268-d35f-4779-b554-fad7eef62494'), AIMessage(content='I appreciate the detailed critique and recommendations. Here are a few revised Twitter posts that address your suggestions:\\n\\n**Revised Post 1: Adding a statistic and a bold statement**\\n\\n\"AI-generated content is changing the game! With up to 30% higher engagement rates than human-created content, I predict that AI agents will revolutionize content creation by 2025! What do you think? Will AI take over content creation? Share your thoughts! #AIContent #FutureOfWork\"\\n\\n**Revised Post 2: Adding a visual element and a clear CTA**\\n\\nHere\\'s a revised tweet with a simple graphic:\\n\\n[Visual: A bold headline reads \"AI Takes Over Content Creation\" with a few statistics below]\\n\\n\"Get ready for the AI revolution in content creation! By 2025, AI is predicted to dominate most industries. Share your thoughts: Will AI agents take over content creation? Take our poll and join the conversation! [link to poll] #AIContent #FutureOfWork\"\\n\\n**Revised Post 3: Adding a brief example and a thought-provoking question**\\n\\n\"Ever wondered how AI-generated content can outperform human-created content? For example, AI-generated blog posts can reduce production time by 75%! As AI agents become more capable, we must ask: Where does the creative value lie? Share your thoughts! #AIContent #FutureOfWork\"\\n\\nLet me know if these revised posts better address your critique and recommendations!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'I appreciate the detailed critique and recommendations. Here are a few revised Twitter posts that address your suggestions:\\n\\n**Revised Post 1: Adding a statistic and a bold statement**\\n\\n\"AI-generated content is changing the game! With up to 30% higher engagement rates than human-created content, I predict that AI agents will revolutionize content creation by 2025! What do you think? Will AI take over content creation? Share your thoughts! #AIContent #FutureOfWork\"\\n\\n**Revised Post 2: Adding a visual element and a clear CTA**\\n\\nHere\\'s a revised tweet with a simple graphic:\\n\\n[Visual: A bold headline reads \"AI Takes Over Content Creation\" with a few statistics below]\\n\\n\"Get ready for the AI revolution in content creation! By 2025, AI is predicted to dominate most industries. Share your thoughts: Will AI agents take over content creation? Take our poll and join the conversation! [link to poll] #AIContent #FutureOfWork\"\\n\\n**Revised Post 3: Adding a brief example and a thought-provoking question**\\n\\n\"Ever wondered how AI-generated content can outperform human-created content? For example, AI-generated blog posts can reduce production time by 75%! As AI agents become more capable, we must ask: Where does the creative value lie? Share your thoughts! #AIContent #FutureOfWork\"\\n\\nLet me know if these revised posts better address your critique and recommendations!', 'token_usage': {'prompt_tokens': 672, 'total_tokens': 962, 'completion_tokens': 290}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-70b-instruct'}, id='run--db252f87-57f2-4972-835a-fb4153d9cbc1-0', usage_metadata={'input_tokens': 672, 'output_tokens': 290, 'total_tokens': 962}, role='assistant'), HumanMessage(content='I\\'d love to provide a follow-up critique and suggestions for your revised posts.\\n\\n**Revised Post 1: Grade B+ (88%)**\\n\\n* Strengths: Adding a statistic and a bold prediction makes the tweet more engaging and informative. The language is concise and attention-grabbing.\\n* Weaknesses: The tweet still feels a bit short and lacks a clear CTA. Consider adding a question or a prompt to encourage users to share their thoughts.\\n\\n**Revised Post 2: Grade A- (92%)**\\n\\n* Strengths: The visual element adds a lot of value to the tweet, making it more eye-catching and engaging. The clear CTA (\"Take our poll and join the conversation!\") encourages users to participate.\\n* Weaknesses: The tweet feels a bit too sales-y, with the poll link potentially being seen as promotional. Consider making the CTA more conversational and focused on sparking a discussion.\\n\\n**Revised Post 3: Grade A (95%)**\\n\\n* Strengths: The brief example and thought-provoking question make the tweet more engaging and informative. The language is concise and encourages users to think critically about the topic.\\n* Weaknesses: The tweet could benefit from a clearer CTA or a more direct question to encourage users to share their thoughts.\\n\\n**Additional Recommendations:**\\n\\n1. **Experiment with humor and personality:** While your revised posts are more engaging, they still feel somewhat formal. Consider adding a bit of humor or personality to your tweets to make them more relatable and human.\\n2. **Use relevant emojis:** Emojis can add a lot of flavor to your tweets and make them more visually appealing. Consider using relevant emojis to break up the text and add tone to your tweets.\\n3. **Encourage conversation, not just engagement:** While engagement metrics like likes and retweets are important, consider focusing on sparking meaningful conversations and debates on Twitter. Use questions, prompts, or thought-provoking statements to encourage users to share their thoughts and engage with each other.\\n\\nBy incorporating these suggestions, you can make your tweets even more engaging, informative, and effective at sparking conversations on Twitter.', additional_kwargs={}, response_metadata={}, id='7d507d41-beca-47be-a23b-3783e6e977c6'), AIMessage(content='Thank you for the detailed critique and suggestions. I appreciate your insight and guidance. Here are a few revised Twitter posts that address your suggestions:\\n\\n**Revised Post 1 (New): Adding a question and a bit of personality**\\n\\n\"AI-generated content is taking over! 💥 With up to 30% higher engagement rates, I\\'m predicting a robot uprising in content creation by 2025! 😱 But seriously, what does this mean for human creatives? Will we become redundant or just really good editors? Share your thoughts! 💬 #AIContent #FutureOfWork\"\\n\\n**Revised Post 2 (New): Making the CTA more conversational and focused on sparking a discussion**\\n\\nHere\\'s a revised tweet with a more conversational CTA:\\n\\n[Visual: A bold headline reads \"AI Takes Over Content Creation\" with a few statistics below]\\n\\n\"Let\\'s talk about the future of content creation! 🤔 With AI on the rise, we need to ask: What role will humans play in content creation? Will we work together or compete with machines? Share your thoughts and let\\'s discuss! 💬 #AIContent #FutureOfWork\"\\n\\n**Revised Post 3 (New): Adding a clearer CTA and using relevant emojis**\\n\\nHere\\'s a revised tweet with a clearer CTA and some added emojis:\\n\\n\"Ever wondered how AI-generated content can outperform human-created content? 🤔 For example, AI-generated blog posts can reduce production time by 75%! 🚀 But where does the creative value lie? 🤷\\u200d♂️ Share your thoughts and let\\'s explore this together! 💡 #AIContent #FutureOfWork\"\\n\\nI\\'ve incorporated your suggestions by adding a bit of humor and personality to the tweets, using relevant emojis to break up the text, and focusing on sparking meaningful conversations rather than just engagement. Let me know if these revised posts better address your critique and recommendations!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Thank you for the detailed critique and suggestions. I appreciate your insight and guidance. Here are a few revised Twitter posts that address your suggestions:\\n\\n**Revised Post 1 (New): Adding a question and a bit of personality**\\n\\n\"AI-generated content is taking over! 💥 With up to 30% higher engagement rates, I\\'m predicting a robot uprising in content creation by 2025! 😱 But seriously, what does this mean for human creatives? Will we become redundant or just really good editors? Share your thoughts! 💬 #AIContent #FutureOfWork\"\\n\\n**Revised Post 2 (New): Making the CTA more conversational and focused on sparking a discussion**\\n\\nHere\\'s a revised tweet with a more conversational CTA:\\n\\n[Visual: A bold headline reads \"AI Takes Over Content Creation\" with a few statistics below]\\n\\n\"Let\\'s talk about the future of content creation! 🤔 With AI on the rise, we need to ask: What role will humans play in content creation? Will we work together or compete with machines? Share your thoughts and let\\'s discuss! 💬 #AIContent #FutureOfWork\"\\n\\n**Revised Post 3 (New): Adding a clearer CTA and using relevant emojis**\\n\\nHere\\'s a revised tweet with a clearer CTA and some added emojis:\\n\\n\"Ever wondered how AI-generated content can outperform human-created content? 🤔 For example, AI-generated blog posts can reduce production time by 75%! 🚀 But where does the creative value lie? 🤷\\u200d♂️ Share your thoughts and let\\'s explore this together! 💡 #AIContent #FutureOfWork\"\\n\\nI\\'ve incorporated your suggestions by adding a bit of humor and personality to the tweets, using relevant emojis to break up the text, and focusing on sparking meaningful conversations rather than just engagement. Let me know if these revised posts better address your critique and recommendations!', 'token_usage': {'prompt_tokens': 1405, 'total_tokens': 1792, 'completion_tokens': 387}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-70b-instruct'}, id='run--9ea98eef-6de3-4231-ad92-5c4d447a58c0-0', usage_metadata={'input_tokens': 1405, 'output_tokens': 387, 'total_tokens': 1792}, role='assistant')]\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c502b",
   "metadata": {
    "papermill": {
     "duration": 0.007949,
     "end_time": "2025-08-08T05:41:49.796898",
     "exception": false,
     "start_time": "2025-08-08T05:41:49.788949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 59.377313,
   "end_time": "2025-08-08T05:41:50.627008",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-08T05:40:51.249695",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
